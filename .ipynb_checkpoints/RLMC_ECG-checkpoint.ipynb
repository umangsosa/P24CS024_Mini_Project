{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a127aa59-019c-4d34-8f9c-c6f1052d5a0f",
   "metadata": {},
   "source": [
    "# Dataset note:\n",
    "# Dataset Downloaded from: https://www.physionet.org/content/mitdb/1.0.0/\n",
    "# Download Link: https://www.physionet.org/static/published-projects/mitdb/mit-bih-arrhythmia-database-1.0.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2618081-d42d-49bf-bd49-4674c3e0ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 11:13:31.353642: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746164611.408219    4973 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746164611.425276    4973 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746164611.525628    4973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746164611.525664    4973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746164611.525665    4973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746164611.525667    4973 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-02 11:13:31.539689: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG record loaded: mit-bih-arrhythmia-database-1.0.0/100\n",
      "Sampling frequency: 360 Hz\n",
      "Total samples: 60000\n",
      "Duration: 166.67 seconds\n",
      "ECG signal shape: (60000,), dtype: float32\n",
      "Time array shape: (60000,), dtype: float64\n",
      "Training samples: 47856\n",
      "Testing samples: 11964\n",
      "X_train shape: (47856, 180, 1), y_train shape: (47856, 1, 1)\n",
      "X_test shape: (11964, 180, 1), y_test shape: (11964, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746164617.794405    4973 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2292 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 11:13:38.673565: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31010400 exceeds 10% of free system memory.\n",
      "2025-05-02 11:13:38.705560: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31010400 exceeds 10% of free system memory.\n",
      "I0000 00:00:1746164620.161133    5106 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 3.7855e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 5.7439e-04 - val_loss: 2.1675e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 3.3931e-04 - val_loss: 1.3525e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 2.5847e-04 - val_loss: 1.0208e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 2.4234e-04 - val_loss: 1.0341e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 2.2029e-04 - val_loss: 9.8728e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 1.9586e-04 - val_loss: 9.5176e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 2.2239e-04 - val_loss: 1.4890e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 1.9915e-04 - val_loss: 9.2472e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 1.9648e-04 - val_loss: 8.8897e-05\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 11:16:09.159043: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31010400 exceeds 10% of free system memory.\n",
      "2025-05-02 11:16:09.176214: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31010400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 1.7262e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 3.1757e-04 - val_loss: 1.2063e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 2.6259e-04 - val_loss: 1.0526e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 2.2925e-04 - val_loss: 1.5581e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 2.4059e-04 - val_loss: 1.1387e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 2.3510e-04 - val_loss: 1.5111e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 2.2579e-04 - val_loss: 1.0518e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 2.1704e-04 - val_loss: 1.4810e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 2.0012e-04 - val_loss: 1.0836e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 1.8732e-04 - val_loss: 9.4867e-05\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 11:18:37.502522: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31010400 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746164918.379999    5107 service.cc:152] XLA service 0x7f901c31a940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746164918.380019    5107 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-05-02 11:18:38.413541: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  73/1346\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746164920.312560    5107 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0014\n",
      "Epoch 2/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 9.6396e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.8857e-04 - val_loss: 8.5955e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.5474e-04 - val_loss: 6.6974e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7.8022e-04 - val_loss: 6.6145e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7.4752e-04 - val_loss: 5.8968e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.2592e-04 - val_loss: 6.1171e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.4276e-04 - val_loss: 5.5268e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.9538e-04 - val_loss: 5.0974e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.6019e-04 - val_loss: 5.0157e-04\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 7.8946e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.5168e-04 - val_loss: 9.3617e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.6599e-04 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "\u001b[1m1346/1346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0320e-04 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "\u001b[1m 164/1346\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7469e-04"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive Agg backend for saving plots\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Input, Dropout, Conv1D, MaxPooling1D, Flatten, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import wfdb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MIT-BIH Arrhythmia Database (record 100, first 60,000 samples)\n",
    "record_path = 'mit-bih-arrhythmia-database-1.0.0/100'\n",
    "try:\n",
    "    record = wfdb.rdrecord(record_path)\n",
    "    ecg_signal = record.p_signal[:60000, 0]  # Use first 60,000 samples, MLII lead\n",
    "    fs = record.fs  # Sampling frequency (360 Hz)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading record {record_path}: {e}\")\n",
    "    raise\n",
    "\n",
    "# Convert to NumPy array and check for invalid values\n",
    "ecg_signal = np.asarray(ecg_signal, dtype=np.float32)\n",
    "if np.any(np.isnan(ecg_signal)) or np.any(np.isinf(ecg_signal)):\n",
    "    print(\"Warning: ECG signal contains NaN or inf values. Replacing with zeros.\")\n",
    "    ecg_signal = np.nan_to_num(ecg_signal, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(f\"ECG record loaded: {record_path}\")\n",
    "print(f\"Sampling frequency: {fs} Hz\")\n",
    "print(f\"Total samples: {len(ecg_signal)}\")\n",
    "print(f\"Duration: {len(ecg_signal) / fs:.2f} seconds\")\n",
    "print(f\"ECG signal shape: {ecg_signal.shape}, dtype: {ecg_signal.dtype}\")\n",
    "\n",
    "# Create time array\n",
    "time = np.arange(len(ecg_signal)) / fs\n",
    "print(f\"Time array shape: {time.shape}, dtype: {time.dtype}\")\n",
    "\n",
    "# Plot raw ECG signal (first 10 seconds)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(time[:int(10 * fs)], ecg_signal[:int(10 * fs)])\n",
    "plt.title('Raw ECG Signal (Record 100, MLII Lead, First 10 Seconds)')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude (mV)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ecg_raw_signal.png')\n",
    "plt.close()\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ecg_scaled = scaler.fit_transform(ecg_signal.reshape(-1, 1))\n",
    "\n",
    "# Plot a sample sequence\n",
    "sequence_length = 180  # ~0.5 seconds at 360 Hz\n",
    "horizon = 1  # Predict 1 sample ahead\n",
    "sample_idx = 1000\n",
    "sample_seq = ecg_scaled[sample_idx:sample_idx + sequence_length]\n",
    "sample_target = ecg_scaled[sample_idx + sequence_length:sample_idx + sequence_length + horizon]\n",
    "sample_time = np.arange(sequence_length + horizon) / fs\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sample_time[:sequence_length], sample_seq, label='Input Sequence (180 samples)')\n",
    "plt.plot(sample_time[sequence_length:], sample_target, 'ro', label='Target (1 sample)')\n",
    "plt.title('Sample ECG Sequence for Training')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Normalized Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ecg_sample_sequence.png')\n",
    "plt.close()\n",
    "\n",
    "# Function to create sequences for time series prediction\n",
    "def create_sequences(data, seq_length, horizon=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - horizon + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length:i+seq_length+horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Parameters\n",
    "test_split = 0.2  # Use 20% of data for testing\n",
    "\n",
    "# Prepare the data\n",
    "X, y = create_sequences(ecg_scaled, sequence_length, horizon)\n",
    "split_idx = int(len(X) * (1 - test_split))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Base Models Implementation\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# 1. LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 2. GRU model\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        GRU(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 3. CNN model\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 4. MLP model\n",
    "def build_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 5. Simple Autoregressive model\n",
    "def ar_forecast(X):\n",
    "    return X[:, -horizon:, :]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Train Base Models\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "input_shape = (sequence_length, 1)\n",
    "\n",
    "# Train LSTM\n",
    "lstm_model = build_lstm_model(input_shape)\n",
    "lstm_history = lstm_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                              epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "lstm_preds = lstm_model.predict(X_test)\n",
    "lstm_preds = lstm_preds.reshape(lstm_preds.shape[0], horizon, 1)\n",
    "\n",
    "# Train GRU\n",
    "gru_model = build_gru_model(input_shape)\n",
    "gru_history = gru_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                            epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "gru_preds = gru_model.predict(X_test)\n",
    "gru_preds = gru_preds.reshape(gru_preds.shape[0], horizon, 1)\n",
    "\n",
    "# Train CNN\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "cnn_history = cnn_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                           epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "cnn_preds = cnn_model.predict(X_test)\n",
    "cnn_preds = cnn_preds.reshape(cnn_preds.shape[0], horizon, 1)\n",
    "\n",
    "# Train MLP\n",
    "mlp_model = build_mlp_model(input_shape)\n",
    "mlp_history = mlp_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                           epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "mlp_preds = mlp_model.predict(X_test)\n",
    "mlp_preds = mlp_preds.reshape(mlp_preds.shape[0], horizon, 1)\n",
    "\n",
    "# AR forecast\n",
    "ar_preds = ar_forecast(X_test)\n",
    "\n",
    "# Verify predictions shapes\n",
    "print(f\"LSTM predictions shape: {lstm_preds.shape}\")\n",
    "print(f\"GRU predictions shape: {gru_preds.shape}\")\n",
    "print(f\"CNN predictions shape: {cnn_preds.shape}\")\n",
    "print(f\"MLP predictions shape: {mlp_preds.shape}\")\n",
    "print(f\"AR predictions shape: {ar_preds.shape}\")\n",
    "print(f\"Target shape: {y_test.shape}\")\n",
    "\n",
    "# Evaluate base models\n",
    "base_models = ['LSTM', 'GRU', 'CNN', 'MLP', 'AR']\n",
    "predictions = [lstm_preds, gru_preds, cnn_preds, mlp_preds, ar_preds]\n",
    "\n",
    "for name, pred in zip(base_models, predictions):\n",
    "    mae = mean_absolute_error(y_test.reshape(-1, 1), pred.reshape(-1, 1))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.reshape(-1, 1), pred.reshape(-1, 1)))\n",
    "    print(f\"{name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# RLMC Implementation (Actor-Critic with DDPG)\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "def create_state_representation(x_seq, model_histories):\n",
    "    if len(model_histories) > 0:\n",
    "        model_features = np.array(model_histories[-1])\n",
    "        if np.std(model_features) > 0:\n",
    "            model_features = (model_features - np.mean(model_features)) / np.std(model_features)\n",
    "    else:\n",
    "        model_features = np.zeros(len(base_models))\n",
    "    time_features = x_seq.flatten()\n",
    "    state = np.concatenate([time_features, model_features])\n",
    "    return state.reshape(1, -1)\n",
    "\n",
    "# Actor Network\n",
    "def build_actor_network(state_dim, action_dim):\n",
    "    inputs = Input(shape=(state_dim,))\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(action_dim, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Critic Network\n",
    "def build_critic_network(state_dim, action_dim):\n",
    "    state_input = Input(shape=(state_dim,))\n",
    "    state_out = Dense(256, activation='relu')(state_input)\n",
    "    state_out = Dense(128, activation='relu')(state_out)\n",
    "    action_input = Input(shape=(action_dim,))\n",
    "    action_out = Dense(128, activation='relu')(action_input)\n",
    "    concat = Concatenate()([state_out, action_out])\n",
    "    x = Dense(64, activation='relu')(concat)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    model = Model([state_input, action_input], outputs)\n",
    "    return model\n",
    "\n",
    "# DDPG Agent for RLMC\n",
    "class RLMCAgent:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.memory = []\n",
    "        self.max_memory_size = 1000\n",
    "        self.batch_size = 64\n",
    "        self.gamma = 0.95\n",
    "        self.tau = 0.005\n",
    "        self.actor = build_actor_network(state_dim, action_dim)\n",
    "        self.actor_target = build_actor_network(state_dim, action_dim)\n",
    "        self.actor_target.set_weights(self.actor.get_weights())\n",
    "        self.actor_optimizer = Adam(learning_rate=0.001)\n",
    "        self.critic = build_critic_network(state_dim, action_dim)\n",
    "        self.critic_target = build_critic_network(state_dim, action_dim)\n",
    "        self.critic_target.set_weights(self.critic.get_weights())\n",
    "        self.critic_optimizer = Adam(learning_rate=0.002)\n",
    "\n",
    "    def get_action(self, state, explore=True):\n",
    "        action = self.actor.predict(state, verbose=0)[0]\n",
    "        if explore:\n",
    "            noise = np.random.normal(0, 0.1, size=self.action_dim)\n",
    "            action = action + noise\n",
    "            action = np.maximum(action, 0)\n",
    "            action_sum = np.sum(action)\n",
    "            if action_sum > 0:\n",
    "                action = action / action_sum\n",
    "        return action\n",
    "\n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "        if len(self.memory) > self.max_memory_size:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        indices = np.random.choice(len(self.memory), self.batch_size, replace=False)\n",
    "        states, actions, rewards, next_states = [], [], [], []\n",
    "        for i in indices:\n",
    "            states.append(self.memory[i][0][0])\n",
    "            actions.append(self.memory[i][1])\n",
    "            rewards.append(self.memory[i][2])\n",
    "            next_states.append(self.memory[i][3][0])\n",
    "        states = tf.convert_to_tensor(np.array(states), dtype=tf.float32)\n",
    "        actions = tf.convert_to_tensor(np.array(actions), dtype=tf.float32)\n",
    "        rewards = tf.convert_to_tensor(np.array(rewards).reshape(-1, 1), dtype=tf.float32)\n",
    "        next_states = tf.convert_to_tensor(np.array(next_states), dtype=tf.float32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.actor_target(next_states)\n",
    "            target_q_values = self.critic_target([next_states, target_actions])\n",
    "            target_q = rewards + self.gamma * target_q_values\n",
    "            current_q = self.critic([states, actions])\n",
    "            critic_loss = tf.reduce_mean(tf.square(target_q - current_q))\n",
    "        critic_grads = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        if None in critic_grads or any(tf.reduce_any(tf.math.is_nan(g)) for g in critic_grads if g is not None):\n",
    "            print(\"Warning: Some critic gradients are None or contain NaN. Skipping critic update.\")\n",
    "        else:\n",
    "            self.critic_optimizer.apply_gradients(zip(critic_grads, self.critic.trainable_variables))\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions_pred = self.actor(states)\n",
    "            actor_loss = -tf.reduce_mean(self.critic([states, actions_pred]))\n",
    "        actor_grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        if None in actor_grads or any(tf.reduce_any(tf.math.is_nan(g)) for g in actor_grads if g is not None):\n",
    "            print(\"Warning: Some actor gradients are None or contain NaN. Skipping actor update.\")\n",
    "        else:\n",
    "            self.actor_optimizer.apply_gradients(zip(actor_grads, self.actor.trainable_variables))\n",
    "        self._update_target_networks()\n",
    "\n",
    "    def _update_target_networks(self):\n",
    "        actor_weights = self.actor.get_weights()\n",
    "        actor_target_weights = self.actor_target.get_weights()\n",
    "        for i in range(len(actor_weights)):\n",
    "            actor_target_weights[i] = self.tau * actor_weights[i] + (1 - self.tau) * actor_target_weights[i]\n",
    "        self.actor_target.set_weights(actor_target_weights)\n",
    "        critic_weights = self.critic.get_weights()\n",
    "        critic_target_weights = self.critic_target.get_weights()\n",
    "        for i in range(len(critic_weights)):\n",
    "            critic_target_weights[i] = self.tau * critic_weights[i] + (1 - self.tau) * critic_target_weights[i]\n",
    "        self.critic_target.set_weights(critic_target_weights)\n",
    "\n",
    "# Reward function\n",
    "def compute_reward(predicted, actual, base_predictions):\n",
    "    predicted = predicted.reshape(-1)\n",
    "    actual = actual.reshape(-1)\n",
    "    base_predictions = [p.reshape(-1) for p in base_predictions]\n",
    "    epsilon = 1e-10\n",
    "    error = np.abs(predicted - actual) / (np.abs(predicted) + np.abs(actual) + epsilon)\n",
    "    smape = 200 * error.mean()\n",
    "    base_errors = []\n",
    "    for pred in base_predictions:\n",
    "        err = np.abs(pred - actual) / (np.abs(pred) + np.abs(actual) + epsilon)\n",
    "        base_errors.append(200 * err.mean())\n",
    "    rank = sum(1 for e in base_errors if e < smape)\n",
    "    rank_normalized = 1 - 2 * (rank / len(base_models))\n",
    "    error_quantile = np.searchsorted(sorted(base_errors + [smape]), smape) / 10\n",
    "    error_normalized = 1 - 2 * (error_quantile / 9)\n",
    "    alpha = 0.5\n",
    "    reward = alpha * error_normalized + rank_normalized\n",
    "    return reward\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Train the RLMC model\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "val_split = int(len(X_test) * 0.5)\n",
    "X_val, X_rlmc_test = X_test[:val_split], X_test[val_split:]\n",
    "y_val, y_rlmc_test = y_test[:val_split], y_test[val_split:]\n",
    "\n",
    "print(f\"Validation set shape: X_val {X_val.shape}, y_val {y_val.shape}\")\n",
    "print(f\"RLMC test set shape: X_rlmc_test {X_rlmc_test.shape}, y_rlmc_test {y_rlmc_test.shape}\")\n",
    "\n",
    "val_base_preds = [\n",
    "    lstm_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    gru_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    cnn_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    mlp_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    ar_forecast(X_val)\n",
    "]\n",
    "\n",
    "for i, name in enumerate(base_models):\n",
    "    print(f\"{name} val predictions shape: {val_base_preds[i].shape}\")\n",
    "\n",
    "state_dim = sequence_length + len(base_models)\n",
    "action_dim = len(base_models)\n",
    "rlmc_agent = RLMCAgent(state_dim, action_dim)\n",
    "\n",
    "n_episodes = 15\n",
    "model_histories = [np.zeros(len(base_models))]\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    total_reward = 0\n",
    "    for t in range(len(X_val) - 1):\n",
    "        state = create_state_representation(X_val[t], model_histories)\n",
    "        action = rlmc_agent.get_action(state)\n",
    "        ensemble_pred = np.zeros_like(y_val[t])\n",
    "        for i, weight in enumerate(action):\n",
    "            ensemble_pred += weight * val_base_preds[i][t]\n",
    "        reward = compute_reward(ensemble_pred, y_val[t], [pred[t] for pred in val_base_preds])\n",
    "        total_reward += reward\n",
    "        current_errors = []\n",
    "        for pred in val_base_preds:\n",
    "            err = np.abs(pred[t] - y_val[t]).mean()\n",
    "            current_errors.append(err)\n",
    "        if len(model_histories) >= 5:\n",
    "            model_histories.pop(0)\n",
    "        model_histories.append(current_errors)\n",
    "        next_state = create_state_representation(X_val[t+1], model_histories)\n",
    "        rlmc_agent.remember(state, action, reward, next_state)\n",
    "        rlmc_agent.replay()\n",
    "    print(f\"Episode {episode+1}/{n_episodes}, Average Reward: {total_reward/len(X_val):.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Evaluate RLMC on test set\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "test_base_preds = [\n",
    "    lstm_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    gru_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    cnn_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    mlp_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    ar_forecast(X_rlmc_test)\n",
    "]\n",
    "\n",
    "rlmc_preds = np.zeros_like(y_rlmc_test)\n",
    "model_weights_history = []\n",
    "model_histories = [np.zeros(len(base_models))]\n",
    "\n",
    "for t in range(len(X_rlmc_test)):\n",
    "    if t > 0:\n",
    "        current_errors = []\n",
    "        for pred in test_base_preds:\n",
    "            err = np.abs(pred[t-1] - y_rlmc_test[t-1]).mean()\n",
    "            current_errors.append(err)\n",
    "        if len(model_histories) >= 5:\n",
    "            model_histories.pop(0)\n",
    "        model_histories.append(current_errors)\n",
    "    state = create_state_representation(X_rlmc_test[t], model_histories)\n",
    "    action = rlmc_agent.get_action(state, explore=False)\n",
    "    model_weights_history.append(action)\n",
    "    for i, weight in enumerate(action):\n",
    "        rlmc_preds[t] += weight * test_base_preds[i][t]\n",
    "\n",
    "y_rlmc_test_flat = y_rlmc_test.reshape(-1, 1)\n",
    "rlmc_preds_flat = rlmc_preds.reshape(-1, 1)\n",
    "rlmc_preds_rescaled = scaler.inverse_transform(rlmc_preds_flat)\n",
    "y_test_rescaled = scaler.inverse_transform(y_rlmc_test_flat)\n",
    "\n",
    "base_preds_rescaled = []\n",
    "for pred in test_base_preds:\n",
    "    base_preds_rescaled.append(scaler.inverse_transform(pred.reshape(-1, 1)))\n",
    "\n",
    "rlmc_mae = mean_absolute_error(y_test_rescaled, rlmc_preds_rescaled)\n",
    "rlmc_rmse = np.sqrt(mean_squared_error(y_test_rescaled, rlmc_preds_rescaled))\n",
    "\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(f\"RLMC - MAE: {rlmc_mae:.4f}, RMSE: {rlmc_rmse:.4f}\")\n",
    "\n",
    "# Plot the results (first 1000 samples)\n",
    "time_steps = np.arange(len(y_test_rescaled)) / fs\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(time_steps[:1000], y_test_rescaled[:1000], label='Actual ECG Signal')\n",
    "plt.plot(time_steps[:1000], rlmc_preds_rescaled[:1000], label='RLMC Prediction')\n",
    "for i, (name, pred) in enumerate(zip(base_models, base_preds_rescaled)):\n",
    "    if i < 3:\n",
    "        plt.plot(time_steps[:1000], pred[:1000], label=f'{name} Prediction', alpha=0.5)\n",
    "plt.title('ECG Signal Prediction with RLMC')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude (mV)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ecg_prediction.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot model weights over time\n",
    "model_weights = np.array(model_weights_history)\n",
    "plt.figure(figsize=(14, 7))\n",
    "for i, name in enumerate(base_models):\n",
    "    plt.plot(model_weights[:, i], label=f'{name} Weight')\n",
    "plt.title('RLMC Model Weights Over Time')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Weight')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_weights.png')\n",
    "plt.close()\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\nComparison of All Models:\")\n",
    "base_maes = []\n",
    "base_rmses = []\n",
    "\n",
    "for i, (name, pred) in enumerate(zip(base_models, base_preds_rescaled)):\n",
    "    mae = mean_absolute_error(y_test_rescaled, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, pred))\n",
    "    base_maes.append(mae)\n",
    "    base_rmses.append(rmse)\n",
    "    print(f\"{name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "avg_ensemble_pred = np.mean(base_preds_rescaled, axis=0)\n",
    "avg_mae = mean_absolute_error(y_test_rescaled, avg_ensemble_pred)\n",
    "avg_rmse = np.sqrt(mean_squared_error(y_test_rescaled, avg_ensemble_pred))\n",
    "print(f\"Average Ensemble - MAE: {avg_mae:.4f}, RMSE: {avg_rmse:.4f}\")\n",
    "print(f\"RLMC - MAE: {rlmc_mae:.4f}, RMSE: {rlmc_rmse:.4f}\")\n",
    "\n",
    "best_base_mae = min(base_maes)\n",
    "improvement_over_best = ((best_base_mae - rlmc_mae) / best_base_mae) * 100\n",
    "improvement_over_avg = ((avg_mae - rlmc_mae) / avg_mae) * 100\n",
    "\n",
    "print(f\"\\nRLMC improvement over best base model: {improvement_over_best:.2f}%\")\n",
    "print(f\"RLMC improvement over average ensemble: {improvement_over_avg:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
