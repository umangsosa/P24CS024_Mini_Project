{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5dc9b42-5041-4b58-b41f-8696ec573880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG record loaded: mit-bih-arrhythmia-database-1.0.0/100\n",
      "Sampling frequency: 360 Hz\n",
      "Total samples: 60000\n",
      "Duration: 166.67 seconds\n",
      "ECG signal shape: (60000,), dtype: float32\n",
      "Time array shape: (60000,), dtype: float64\n",
      "Training samples: 47808\n",
      "Testing samples: 11953\n",
      "X_train shape: (47808, 180, 1), y_train shape: (47808, 60, 1)\n",
      "X_test shape: (11953, 180, 1), y_test shape: (11953, 60, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746262843.348395 3464133 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1210 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:30:44.498828: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30979440 exceeds 10% of free system memory.\n",
      "2025-05-03 14:30:44.548223: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30979440 exceeds 10% of free system memory.\n",
      "I0000 00:00:1746262845.986198 3464328 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0120 - val_loss: 0.0058\n",
      "Epoch 2/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 3/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 4/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 5/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 6/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:33:15.288935: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30979440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 2/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 3/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 4/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 6/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:35:48.759397: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30979440 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746263149.514653 3464324 service.cc:152] XLA service 0x55f317afbe00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746263149.514681 3464324 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-05-03 14:35:49.551320: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  72/1345\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746263152.822451 3464324 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 0.0062\n",
      "Epoch 2/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 3/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 4/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 5/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 6/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 7/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 8/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:36:28.630859: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30979440 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 2/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 3/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 4/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 6/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 7/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 8/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "\u001b[1m1345/1345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "LSTM predictions shape: (11953, 60, 1)\n",
      "GRU predictions shape: (11953, 60, 1)\n",
      "CNN predictions shape: (11953, 60, 1)\n",
      "MLP predictions shape: (11953, 60, 1)\n",
      "AR predictions shape: (11953, 60, 1)\n",
      "Target shape: (11953, 60, 1)\n",
      "LSTM - MAE: 0.0224, RMSE: 0.0550\n",
      "GRU - MAE: 0.0237, RMSE: 0.0566\n",
      "CNN - MAE: 0.0232, RMSE: 0.0555\n",
      "MLP - MAE: 0.0261, RMSE: 0.0608\n",
      "AR - MAE: 0.0602, RMSE: 0.1265\n",
      "Validation set shape: X_val (5976, 180, 1), y_val (5976, 60, 1)\n",
      "RLMC test set shape: X_rlmc_test (5977, 180, 1), y_rlmc_test (5977, 60, 1)\n",
      "LSTM val predictions shape: (5976, 60, 1)\n",
      "GRU val predictions shape: (5976, 60, 1)\n",
      "CNN val predictions shape: (5976, 60, 1)\n",
      "MLP val predictions shape: (5976, 60, 1)\n",
      "AR val predictions shape: (5976, 60, 1)\n",
      "Episode 1/15, Average Reward: 0.7471\n",
      "Episode 2/15, Average Reward: 0.8218\n",
      "Episode 3/15, Average Reward: 0.8002\n",
      "Episode 4/15, Average Reward: 0.8097\n",
      "Episode 5/15, Average Reward: 0.8005\n",
      "Episode 6/15, Average Reward: 0.8038\n",
      "Episode 7/15, Average Reward: 0.7993\n",
      "Episode 8/15, Average Reward: 0.8031\n",
      "Episode 9/15, Average Reward: 0.8051\n",
      "Episode 10/15, Average Reward: 0.8034\n",
      "Episode 11/15, Average Reward: 0.7978\n",
      "Episode 12/15, Average Reward: 0.8009\n",
      "Episode 13/15, Average Reward: 0.8007\n",
      "Episode 14/15, Average Reward: 0.8003\n",
      "Episode 15/15, Average Reward: 0.8056\n",
      "\n",
      "Final Evaluation Results:\n",
      "RLMC - MAE: 0.0430, RMSE: 0.1082\n",
      "\n",
      "Comparison of All Models:\n",
      "LSTM - MAE: 0.0430, RMSE: 0.1082\n",
      "GRU - MAE: 0.0459, RMSE: 0.1114\n",
      "CNN - MAE: 0.0441, RMSE: 0.1069\n",
      "MLP - MAE: 0.0477, RMSE: 0.1131\n",
      "AR - MAE: 0.1101, RMSE: 0.2322\n",
      "Average Ensemble - MAE: 0.0494, RMSE: 0.1122\n",
      "RLMC - MAE: 0.0430, RMSE: 0.1082\n",
      "\n",
      "RLMC improvement over best base model: 0.00%\n",
      "RLMC improvement over average ensemble: 12.95%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use non-interactive Agg backend for saving plots\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, Input, Dropout, Conv1D, MaxPooling1D, Flatten, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import wfdb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load MIT-BIH Arrhythmia Database (record 100, first 60,000 samples)\n",
    "record_path = 'mit-bih-arrhythmia-database-1.0.0/100'\n",
    "try:\n",
    "    record = wfdb.rdrecord(record_path)\n",
    "    ecg_signal = record.p_signal[:60000, 0]  # Use first 60,000 samples, MLII lead\n",
    "    fs = record.fs  # Sampling frequency (360 Hz)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading record {record_path}: {e}\")\n",
    "    raise\n",
    "\n",
    "# Convert to NumPy array and check for invalid values\n",
    "ecg_signal = np.asarray(ecg_signal, dtype=np.float32)\n",
    "if np.any(np.isnan(ecg_signal)) or np.any(np.isinf(ecg_signal)):\n",
    "    print(\"Warning: ECG signal contains NaN or inf values. Replacing with zeros.\")\n",
    "    ecg_signal = np.nan_to_num(ecg_signal, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(f\"ECG record loaded: {record_path}\")\n",
    "print(f\"Sampling frequency: {fs} Hz\")\n",
    "print(f\"Total samples: {len(ecg_signal)}\")\n",
    "print(f\"Duration: {len(ecg_signal) / fs:.2f} seconds\")\n",
    "print(f\"ECG signal shape: {ecg_signal.shape}, dtype: {ecg_signal.dtype}\")\n",
    "\n",
    "# Create time array\n",
    "time = np.arange(len(ecg_signal)) / fs\n",
    "print(f\"Time array shape: {time.shape}, dtype: {time.dtype}\")\n",
    "\n",
    "# Plot raw ECG signal (first 10 seconds)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(time[:int(10 * fs)], ecg_signal[:int(10 * fs)])\n",
    "plt.title('Raw ECG Signal (Record 100, MLII Lead, First 10 Seconds)')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude (mV)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ecg_raw_signal.png')\n",
    "plt.close()\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ecg_scaled = scaler.fit_transform(ecg_signal.reshape(-1, 1))\n",
    "\n",
    "# Plot a sample sequence\n",
    "sequence_length = 180  # ~0.5 seconds at 360 Hz\n",
    "horizon = 60  # Predict 60 sample ahead\n",
    "sample_idx = 1000\n",
    "sample_seq = ecg_scaled[sample_idx:sample_idx + sequence_length]\n",
    "sample_target = ecg_scaled[sample_idx + sequence_length:sample_idx + sequence_length + horizon]\n",
    "sample_time = np.arange(sequence_length + horizon) / fs\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sample_time[:sequence_length], sample_seq, label='Input Sequence (180 samples)')\n",
    "plt.plot(sample_time[sequence_length:], sample_target, 'ro', label='Target (1 sample)')\n",
    "plt.title('Sample ECG Sequence for Training')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Normalized Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ecg_sample_sequence.png')\n",
    "plt.close()\n",
    "\n",
    "# Function to create sequences for time series prediction\n",
    "def create_sequences(data, seq_length, horizon=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - horizon + 1):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length:i+seq_length+horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Parameters\n",
    "test_split = 0.2  # Use 20% of data for testing\n",
    "\n",
    "# Prepare the data\n",
    "X, y = create_sequences(ecg_scaled, sequence_length, horizon)\n",
    "split_idx = int(len(X) * (1 - test_split))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Base Models Implementation\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# 1. LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 2. GRU model\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        GRU(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 3. CNN model\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 4. MLP model\n",
    "def build_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dense(horizon)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "# 5. Simple Autoregressive model\n",
    "def ar_forecast(X):\n",
    "    return X[:, -horizon:, :]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Train Base Models\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "input_shape = (sequence_length, 1)\n",
    "\n",
    "# Train LSTM\n",
    "lstm_model = build_lstm_model(input_shape)\n",
    "lstm_history = lstm_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                              epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "lstm_preds = lstm_model.predict(X_test)\n",
    "lstm_preds = lstm_preds.reshape(lstm_preds.shape[0], horizon, 1)\n",
    "\n",
    "# Train GRU\n",
    "gru_model = build_gru_model(input_shape)\n",
    "gru_history = gru_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                            epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "gru_preds = gru_model.predict(X_test)\n",
    "gru_preds = gru_preds.reshape(gru_preds.shape[0], horizon, 1)\n",
    "\n",
    "# Train CNN\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "cnn_history = cnn_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                           epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "cnn_preds = cnn_model.predict(X_test)\n",
    "cnn_preds = cnn_preds.reshape(cnn_preds.shape[0], horizon, 1)\n",
    "\n",
    "# Train MLP\n",
    "mlp_model = build_mlp_model(input_shape)\n",
    "mlp_history = mlp_model.fit(X_train, y_train.reshape(y_train.shape[0], horizon),\n",
    "                           epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "mlp_preds = mlp_model.predict(X_test)\n",
    "mlp_preds = mlp_preds.reshape(mlp_preds.shape[0], horizon, 1)\n",
    "\n",
    "# AR forecast\n",
    "ar_preds = ar_forecast(X_test)\n",
    "\n",
    "# Verify predictions shapes\n",
    "print(f\"LSTM predictions shape: {lstm_preds.shape}\")\n",
    "print(f\"GRU predictions shape: {gru_preds.shape}\")\n",
    "print(f\"CNN predictions shape: {cnn_preds.shape}\")\n",
    "print(f\"MLP predictions shape: {mlp_preds.shape}\")\n",
    "print(f\"AR predictions shape: {ar_preds.shape}\")\n",
    "print(f\"Target shape: {y_test.shape}\")\n",
    "\n",
    "# Evaluate base models\n",
    "base_models = ['LSTM', 'GRU', 'CNN', 'MLP', 'AR']\n",
    "predictions = [lstm_preds, gru_preds, cnn_preds, mlp_preds, ar_preds]\n",
    "\n",
    "for name, pred in zip(base_models, predictions):\n",
    "    mae = mean_absolute_error(y_test.reshape(-1, 1), pred.reshape(-1, 1))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.reshape(-1, 1), pred.reshape(-1, 1)))\n",
    "    print(f\"{name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# RLMC Implementation (Actor-Critic with DDPG)\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "def create_state_representation(x_seq, model_histories):\n",
    "    if len(model_histories) > 0:\n",
    "        model_features = np.array(model_histories[-1])\n",
    "        if np.std(model_features) > 0:\n",
    "            model_features = (model_features - np.mean(model_features)) / np.std(model_features)\n",
    "    else:\n",
    "        model_features = np.zeros(len(base_models))\n",
    "    time_features = x_seq.flatten()\n",
    "    state = np.concatenate([time_features, model_features])\n",
    "    return state.reshape(1, -1)\n",
    "\n",
    "# Actor Network\n",
    "def build_actor_network(state_dim, action_dim):\n",
    "    inputs = Input(shape=(state_dim,))\n",
    "    x = Dense(256, activation='relu')(inputs)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    outputs = Dense(action_dim, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Critic Network\n",
    "def build_critic_network(state_dim, action_dim):\n",
    "    state_input = Input(shape=(state_dim,))\n",
    "    state_out = Dense(256, activation='relu')(state_input)\n",
    "    state_out = Dense(128, activation='relu')(state_out)\n",
    "    action_input = Input(shape=(action_dim,))\n",
    "    action_out = Dense(128, activation='relu')(action_input)\n",
    "    concat = Concatenate()([state_out, action_out])\n",
    "    x = Dense(64, activation='relu')(concat)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    model = Model([state_input, action_input], outputs)\n",
    "    return model\n",
    "\n",
    "# DDPG Agent for RLMC\n",
    "class RLMCAgent:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.memory = []\n",
    "        self.max_memory_size = 1000\n",
    "        self.batch_size = 64\n",
    "        self.gamma = 0.95\n",
    "        self.tau = 0.005\n",
    "        self.actor = build_actor_network(state_dim, action_dim)\n",
    "        self.actor_target = build_actor_network(state_dim, action_dim)\n",
    "        self.actor_target.set_weights(self.actor.get_weights())\n",
    "        self.actor_optimizer = Adam(learning_rate=0.001)\n",
    "        self.critic = build_critic_network(state_dim, action_dim)\n",
    "        self.critic_target = build_critic_network(state_dim, action_dim)\n",
    "        self.critic_target.set_weights(self.critic.get_weights())\n",
    "        self.critic_optimizer = Adam(learning_rate=0.002)\n",
    "\n",
    "    def get_action(self, state, explore=True):\n",
    "        action = self.actor.predict(state, verbose=0)[0]\n",
    "        if explore:\n",
    "            noise = np.random.normal(0, 0.1, size=self.action_dim)\n",
    "            action = action + noise\n",
    "            action = np.maximum(action, 0)\n",
    "            action_sum = np.sum(action)\n",
    "            if action_sum > 0:\n",
    "                action = action / action_sum\n",
    "        return action\n",
    "\n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "        if len(self.memory) > self.max_memory_size:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        indices = np.random.choice(len(self.memory), self.batch_size, replace=False)\n",
    "        states, actions, rewards, next_states = [], [], [], []\n",
    "        for i in indices:\n",
    "            states.append(self.memory[i][0][0])\n",
    "            actions.append(self.memory[i][1])\n",
    "            rewards.append(self.memory[i][2])\n",
    "            next_states.append(self.memory[i][3][0])\n",
    "        states = tf.convert_to_tensor(np.array(states), dtype=tf.float32)\n",
    "        actions = tf.convert_to_tensor(np.array(actions), dtype=tf.float32)\n",
    "        rewards = tf.convert_to_tensor(np.array(rewards).reshape(-1, 1), dtype=tf.float32)\n",
    "        next_states = tf.convert_to_tensor(np.array(next_states), dtype=tf.float32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = self.actor_target(next_states)\n",
    "            target_q_values = self.critic_target([next_states, target_actions])\n",
    "            target_q = rewards + self.gamma * target_q_values\n",
    "            current_q = self.critic([states, actions])\n",
    "            critic_loss = tf.reduce_mean(tf.square(target_q - current_q))\n",
    "        critic_grads = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        if None in critic_grads or any(tf.reduce_any(tf.math.is_nan(g)) for g in critic_grads if g is not None):\n",
    "            print(\"Warning: Some critic gradients are None or contain NaN. Skipping critic update.\")\n",
    "        else:\n",
    "            self.critic_optimizer.apply_gradients(zip(critic_grads, self.critic.trainable_variables))\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions_pred = self.actor(states)\n",
    "            actor_loss = -tf.reduce_mean(self.critic([states, actions_pred]))\n",
    "        actor_grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        if None in actor_grads or any(tf.reduce_any(tf.math.is_nan(g)) for g in actor_grads if g is not None):\n",
    "            print(\"Warning: Some actor gradients are None or contain NaN. Skipping actor update.\")\n",
    "        else:\n",
    "            self.actor_optimizer.apply_gradients(zip(actor_grads, self.actor.trainable_variables))\n",
    "        self._update_target_networks()\n",
    "\n",
    "    def _update_target_networks(self):\n",
    "        actor_weights = self.actor.get_weights()\n",
    "        actor_target_weights = self.actor_target.get_weights()\n",
    "        for i in range(len(actor_weights)):\n",
    "            actor_target_weights[i] = self.tau * actor_weights[i] + (1 - self.tau) * actor_target_weights[i]\n",
    "        self.actor_target.set_weights(actor_target_weights)\n",
    "        critic_weights = self.critic.get_weights()\n",
    "        critic_target_weights = self.critic_target.get_weights()\n",
    "        for i in range(len(critic_weights)):\n",
    "            critic_target_weights[i] = self.tau * critic_weights[i] + (1 - self.tau) * critic_target_weights[i]\n",
    "        self.critic_target.set_weights(critic_target_weights)\n",
    "\n",
    "# Reward function\n",
    "def compute_reward(predicted, actual, base_predictions):\n",
    "    predicted = predicted.reshape(-1)\n",
    "    actual = actual.reshape(-1)\n",
    "    base_predictions = [p.reshape(-1) for p in base_predictions]\n",
    "    epsilon = 1e-10\n",
    "    error = np.abs(predicted - actual) / (np.abs(predicted) + np.abs(actual) + epsilon)\n",
    "    smape = 200 * error.mean()\n",
    "    base_errors = []\n",
    "    for pred in base_predictions:\n",
    "        err = np.abs(pred - actual) / (np.abs(pred) + np.abs(actual) + epsilon)\n",
    "        base_errors.append(200 * err.mean())\n",
    "    rank = sum(1 for e in base_errors if e < smape)\n",
    "    rank_normalized = 1 - 2 * (rank / len(base_models))\n",
    "    error_quantile = np.searchsorted(sorted(base_errors + [smape]), smape) / 10\n",
    "    error_normalized = 1 - 2 * (error_quantile / 9)\n",
    "    alpha = 0.5\n",
    "    reward = alpha * error_normalized + rank_normalized\n",
    "    return reward\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Train the RLMC model\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "val_split = int(len(X_test) * 0.5)\n",
    "X_val, X_rlmc_test = X_test[:val_split], X_test[val_split:]\n",
    "y_val, y_rlmc_test = y_test[:val_split], y_test[val_split:]\n",
    "\n",
    "print(f\"Validation set shape: X_val {X_val.shape}, y_val {y_val.shape}\")\n",
    "print(f\"RLMC test set shape: X_rlmc_test {X_rlmc_test.shape}, y_rlmc_test {y_rlmc_test.shape}\")\n",
    "\n",
    "val_base_preds = [\n",
    "    lstm_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    gru_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    cnn_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    mlp_model.predict(X_val, verbose=0).reshape(-1, horizon, 1),\n",
    "    ar_forecast(X_val)\n",
    "]\n",
    "\n",
    "for i, name in enumerate(base_models):\n",
    "    print(f\"{name} val predictions shape: {val_base_preds[i].shape}\")\n",
    "\n",
    "state_dim = sequence_length + len(base_models)\n",
    "action_dim = len(base_models)\n",
    "rlmc_agent = RLMCAgent(state_dim, action_dim)\n",
    "\n",
    "n_episodes = 15\n",
    "model_histories = [np.zeros(len(base_models))]\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    total_reward = 0\n",
    "    for t in range(len(X_val) - 1):\n",
    "        state = create_state_representation(X_val[t], model_histories)\n",
    "        action = rlmc_agent.get_action(state)\n",
    "        ensemble_pred = np.zeros_like(y_val[t])\n",
    "        for i, weight in enumerate(action):\n",
    "            ensemble_pred += weight * val_base_preds[i][t]\n",
    "        reward = compute_reward(ensemble_pred, y_val[t], [pred[t] for pred in val_base_preds])\n",
    "        total_reward += reward\n",
    "        current_errors = []\n",
    "        for pred in val_base_preds:\n",
    "            err = np.abs(pred[t] - y_val[t]).mean()\n",
    "            current_errors.append(err)\n",
    "        if len(model_histories) >= 5:\n",
    "            model_histories.pop(0)\n",
    "        model_histories.append(current_errors)\n",
    "        next_state = create_state_representation(X_val[t+1], model_histories)\n",
    "        rlmc_agent.remember(state, action, reward, next_state)\n",
    "        rlmc_agent.replay()\n",
    "    print(f\"Episode {episode+1}/{n_episodes}, Average Reward: {total_reward/len(X_val):.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Evaluate RLMC on test set\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "test_base_preds = [\n",
    "    lstm_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    gru_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    cnn_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    mlp_model.predict(X_rlmc_test, verbose=0).reshape(-1, horizon, 1),\n",
    "    ar_forecast(X_rlmc_test)\n",
    "]\n",
    "\n",
    "rlmc_preds = np.zeros_like(y_rlmc_test)\n",
    "model_weights_history = []\n",
    "model_histories = [np.zeros(len(base_models))]\n",
    "\n",
    "for t in range(len(X_rlmc_test)):\n",
    "    if t > 0:\n",
    "        current_errors = []\n",
    "        for pred in test_base_preds:\n",
    "            err = np.abs(pred[t-1] - y_rlmc_test[t-1]).mean()\n",
    "            current_errors.append(err)\n",
    "        if len(model_histories) >= 5:\n",
    "            model_histories.pop(0)\n",
    "        model_histories.append(current_errors)\n",
    "    state = create_state_representation(X_rlmc_test[t], model_histories)\n",
    "    action = rlmc_agent.get_action(state, explore=False)\n",
    "    model_weights_history.append(action)\n",
    "    for i, weight in enumerate(action):\n",
    "        rlmc_preds[t] += weight * test_base_preds[i][t]\n",
    "\n",
    "y_rlmc_test_flat = y_rlmc_test.reshape(-1, 1)\n",
    "rlmc_preds_flat = rlmc_preds.reshape(-1, 1)\n",
    "rlmc_preds_rescaled = scaler.inverse_transform(rlmc_preds_flat)\n",
    "y_test_rescaled = scaler.inverse_transform(y_rlmc_test_flat)\n",
    "\n",
    "base_preds_rescaled = []\n",
    "for pred in test_base_preds:\n",
    "    base_preds_rescaled.append(scaler.inverse_transform(pred.reshape(-1, 1)))\n",
    "\n",
    "rlmc_mae = mean_absolute_error(y_test_rescaled, rlmc_preds_rescaled)\n",
    "rlmc_rmse = np.sqrt(mean_squared_error(y_test_rescaled, rlmc_preds_rescaled))\n",
    "\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(f\"RLMC - MAE: {rlmc_mae:.4f}, RMSE: {rlmc_rmse:.4f}\")\n",
    "\n",
    "# Plot the results (first 1000 samples)\n",
    "time_steps = np.arange(len(y_test_rescaled)) / fs\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(time_steps[:1000], y_test_rescaled[:1000], label='Actual ECG Signal')\n",
    "plt.plot(time_steps[:1000], rlmc_preds_rescaled[:1000], label='RLMC Prediction')\n",
    "for i, (name, pred) in enumerate(zip(base_models, base_preds_rescaled)):\n",
    "    if i < 3:\n",
    "        plt.plot(time_steps[:1000], pred[:1000], label=f'{name} Prediction', alpha=0.5)\n",
    "plt.title('ECG Signal Prediction with RLMC')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude (mV)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ecg_prediction.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot model weights over time\n",
    "model_weights = np.array(model_weights_history)\n",
    "plt.figure(figsize=(14, 7))\n",
    "for i, name in enumerate(base_models):\n",
    "    plt.plot(model_weights[:, i], label=f'{name} Weight')\n",
    "plt.title('RLMC Model Weights Over Time')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Weight')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_weights.png')\n",
    "plt.close()\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\nComparison of All Models:\")\n",
    "base_maes = []\n",
    "base_rmses = []\n",
    "\n",
    "for i, (name, pred) in enumerate(zip(base_models, base_preds_rescaled)):\n",
    "    mae = mean_absolute_error(y_test_rescaled, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, pred))\n",
    "    base_maes.append(mae)\n",
    "    base_rmses.append(rmse)\n",
    "    print(f\"{name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "avg_ensemble_pred = np.mean(base_preds_rescaled, axis=0)\n",
    "avg_mae = mean_absolute_error(y_test_rescaled, avg_ensemble_pred)\n",
    "avg_rmse = np.sqrt(mean_squared_error(y_test_rescaled, avg_ensemble_pred))\n",
    "print(f\"Average Ensemble - MAE: {avg_mae:.4f}, RMSE: {avg_rmse:.4f}\")\n",
    "print(f\"RLMC - MAE: {rlmc_mae:.4f}, RMSE: {rlmc_rmse:.4f}\")\n",
    "\n",
    "best_base_mae = min(base_maes)\n",
    "improvement_over_best = ((best_base_mae - rlmc_mae) / best_base_mae) * 100\n",
    "improvement_over_avg = ((avg_mae - rlmc_mae) / avg_mae) * 100\n",
    "\n",
    "print(f\"\\nRLMC improvement over best base model: {improvement_over_best:.2f}%\")\n",
    "print(f\"RLMC improvement over average ensemble: {improvement_over_avg:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
